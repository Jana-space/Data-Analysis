{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Import the necessary Libraries:**"],"metadata":{"id":"AMg1whQmbmau"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from sklearn import preprocessing\n","import warnings\n","warnings.filterwarnings('ignore')\n","%matplotlib inline"],"metadata":{"id":"EJI3R_ae3dcZ","executionInfo":{"status":"ok","timestamp":1730716966884,"user_tz":0,"elapsed":7896,"user":{"displayName":"thamil mahal","userId":"17974725994441413831"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["### **Mounting the google drive to the colab environment:**"],"metadata":{"id":"swmzfS3bbvzE"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ekzRnwM31ZA","outputId":"b021e67d-b284-4433-bcdd-d522d6a0bf26","executionInfo":{"status":"ok","timestamp":1730718326027,"user_tz":0,"elapsed":43909,"user":{"displayName":"thamil mahal","userId":"17974725994441413831"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/AQI_India'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4r91f2MP33ag","outputId":"9e9b324b-7283-483f-82db-a475898ef772","executionInfo":{"status":"ok","timestamp":1730718461440,"user_tz":0,"elapsed":258,"user":{"displayName":"thamil mahal","userId":"17974725994441413831"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/AQI_India'\n","/content\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6-j0IMV5Zqh","outputId":"fced6b36-b772-4fcf-b279-35b2e8d77219","executionInfo":{"status":"ok","timestamp":1730718514753,"user_tz":0,"elapsed":235,"user":{"displayName":"thamil mahal","userId":"17974725994441413831"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"markdown","source":["### **Loading the Pandas dataframe:**"],"metadata":{"id":"09eavbBab9yx"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the CSV file into a pandas DataFrame\n","df = pd.read_csv(\"city_day.csv\")\n","df.head()\n"],"metadata":{"id":"gODTwEvY57tn","colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"status":"error","timestamp":1730718443119,"user_tz":0,"elapsed":254,"user":{"displayName":"thamil mahal","userId":"17974725994441413831"}},"outputId":"5d8ce653-6983-4d81-a95c-2e1d05df3770"},"execution_count":7,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'city_day.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-c79f1732a6b3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the CSV file into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"city_day.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'city_day.csv'"]}]},{"cell_type":"markdown","source":["### **Exploratory Data Analysis**"],"metadata":{"id":"WMuM1oN7cR7n"}},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"vYkUTw6sBzGW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#shows columns in list format\n","df.columns"],"metadata":{"id":"fwEkPMGNVFWj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"B7U8eh7NcqOT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Total Number of cities in the dataset**"],"metadata":{"id":"i8lCrRfYa6mM"}},{"cell_type":"code","source":["cities = df['City'].value_counts()\n","print(f'Total number of cities in the dataset : {len(cities)}')\n","cities"],"metadata":{"id":"d4ML0W8QXevv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Convert the Date column into Date Time format**"],"metadata":{"id":"lCBC8GNgbdRR"}},{"cell_type":"markdown","source":["df: This is your DataFrame, which is like a table of data.\n","\n","df['Date']: This selects the \"Date\" column from your table.\n","\n","pd.to_datetime(): This function from the pandas library takes the \"Date\" values and changes them into a date format that Python can work with more easily.\n","\n","**So, in summary, this line converts the \"Date\" column from text (or string) format into an actual date format. This is useful because once the dates are converted, you can do things like sorting the data by date or calculating the time difference between dates.**"],"metadata":{"id":"fSS_KhNThCPO"}},{"cell_type":"code","source":["# convert 'Date' to datetime format as in the original dataframe the type of date column is object\n","df['Date'] = pd.to_datetime(df['Date'])\n","\n","df['month']=pd.DatetimeIndex(df['Date']).month #making a new column by extracting month part of the Date column in cities dataframe\n","df['Year']=pd.DatetimeIndex(df['Date']).year ##making a new column by extracting year part of the Date column in cities dataframe\n"],"metadata":{"id":"G0jZ-erFbc6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"eKZCuX8Dt1C9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"50OYbEykcUqR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Look at the missing values**"],"metadata":{"id":"FtJwe0j8fX0w"}},{"cell_type":"code","source":["# Missing values\n","def missing_values_table(df):\n","        # Total missing values\n","        mis_val = df.isnull().sum()\n","\n","        # Percentage of missing values\n","        mis_val_percent = 100 * df.isnull().sum() / len(df)\n","\n","        # Make a table with the results\n","        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n","        print(mis_val_table)\n","\n","        # Rename the columns\n","        mis_val_table_ren_columns = mis_val_table.rename(\n","        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n","\n","        # Sort the table by percentage of missing descending\n","        mis_val_table_ren_columns = mis_val_table_ren_columns.sort_values(\n","        '% of Total Values', ascending=False)\n","\n","        # Return the dataframe with missing information\n","        return mis_val_table_ren_columns\n","\n","missing_values= missing_values_table(df)\n","missing_values.style.background_gradient(cmap='Oranges')"],"metadata":{"id":"ed9eO5AsfWN0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['PM']=df['PM10']+df['PM2.5']\n","df['Nitric']=df['NO']+df['NO2']+df['NOx']\n","df['BTX']=df['Benzene']+df['Toluene']+df['Xylene']\n","df.head()"],"metadata":{"id":"81BSh7S8yDxT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Creating New DataFrame for Air Quality Index**"],"metadata":{"id":"newooci1tCjv"}},{"cell_type":"code","source":["selected_columns = ['City', 'Date', 'month', 'Year','PM2.5', 'PM10', 'Nitric','NH3', 'CO', 'SO2', 'O3', 'BTX', 'AQI', 'AQI_Bucket']\n","\n","# Create a new DataFrame with only the selected columns\n","df1 = df[selected_columns]\n","\n","# Display the first few rows of the new DataFrame\n","df1.head()\n"],"metadata":{"id":"tawbggXIrhEy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Missing values\n","def missing_values_table(df1):\n","        # Total missing values\n","        mis_val = df1.isnull().sum()\n","\n","        # Percentage of missing values\n","        mis_val_percent = 100 * df1.isnull().sum() / len(df1)\n","\n","        # Make a table with the results\n","        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n","        mis_val_table\n","\n","        # Rename the columns\n","        mis_val_table_ren_columns = mis_val_table.rename(\n","        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n","\n","        # Sort the table by percentage of missing descending\n","        mis_val_table_ren_columns = mis_val_table_ren_columns.sort_values(\n","        '% of Total Values', ascending=False)\n","\n","        # Return the dataframe with missing information\n","        return mis_val_table_ren_columns\n","\n","missing_values= missing_values_table(df1)\n","missing_values.style.background_gradient(cmap='Oranges')"],"metadata":{"id":"7p6y6Zh0tb7V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Imputing missing values**"],"metadata":{"id":"qxnjauwAChAy"}},{"cell_type":"markdown","source":["### **Mean/Median/Mode Imputation**\n","* **Mean:** Replace missing values with the mean of the column.\n","\n","* **Median**: Replace missing values with the median of the column. This is useful if your data has outliers, as the median is less sensitive to them.\n","\n","* **Mode:** Replace missing values with the mode (most frequent value) of the column. This is often used for categorical variables but can be applied to numerical data as well."],"metadata":{"id":"xtP3Y5YyCJJy"}},{"cell_type":"code","source":["pollutants = ['PM2.5', 'PM10', 'Nitric','NH3', 'CO', 'SO2', 'O3', 'BTX','AQI']\n","dff= df1.groupby(['Year','month','City'])[pollutants].mean().reset_index()\n","dff"],"metadata":{"id":"r89YTslNLO4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1['PM2.5']=df1['PM2.5'].fillna((df1['PM2.5'].median()))\n","df1['PM10']=df1['PM10'].fillna((df1['PM10'].median()))\n","df1['Nitric']=df1['Nitric'].fillna((df1['Nitric'].median()))\n","df1['NH3']=df1['NH3'].fillna((df1['NH3'].median()))\n","df1['CO']=df1['CO'].fillna((df1['CO'].median()))\n","df1['SO2']=df1['SO2'].fillna((df1['SO2'].median()))\n","df1['O3']=df1['O3'].fillna((df1['O3'].median()))\n","df1['BTX']=df1['BTX'].fillna((df1['BTX'].median()))\n","df1['AQI']=df1['AQI'].fillna((df1['AQI'].median()))\n","df1['AQI_Bucket']=df1['AQI_Bucket'].fillna('moderate')"],"metadata":{"id":"YhK7DB4LLuCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1"],"metadata":{"id":"va7WqvnNMtIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.describe()"],"metadata":{"id":"eXxwf05pAL4g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Subsetting columns**\n","Even though a lot of columns have been provided in the dataset, we shall select a few prominent ones. Let's create a new dataframe called pollutants containg the major pollutants responsible for air pollution."],"metadata":{"id":"V2q9tyIT8vuZ"}},{"cell_type":"code","source":["pollutants = ['PM2.5', 'PM10', 'Nitric','NH3', 'CO', 'SO2', 'O3', 'BTX','AQI']"],"metadata":{"id":"gklY03xl85Pi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_LlK4ZdN23T","outputId":"b5564b67-d30d-427c-f669-6bd0c773114a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['City', 'Date', 'month', 'Year', 'PM2.5', 'PM10', 'Nitric', 'NH3', 'CO',\n","       'SO2', 'O3', 'BTX', 'AQI', 'AQI_Bucket'],\n","      dtype='object')"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["df.to_csv('/content/drive/MyDrive/CMP7005/AQI_India/aqi_data.csv', index=False)"],"metadata":{"id":"0Uwj256N6xVM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.set_index('Date',inplace=True)\n","axes = df1[pollutants].plot(marker='.', alpha=0.5, linestyle='None', figsize=(16, 20), subplots=True)\n","for ax in axes:\n","\n","    ax.set_xlabel('Years')\n","    ax.set_ylabel('ug / m3')"],"metadata":{"id":"MV-tbtQf89Fn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Year wise plot**"],"metadata":{"id":"Tuy60HwN0r8q"}},{"cell_type":"code","source":["# Group by Year and Month to calculate the monthly average for each pollutant\n","monthly_avg = df1.groupby(['Year', 'month'])[pollutants].mean().reset_index()\n","\n","# Create a Date column from Year and Month\n","monthly_avg['Date'] = pd.to_datetime(monthly_avg[['Year', 'month']].assign(DAY=1))\n","\n","# Plotting the monthly average for each pollutant\n","fig, axes = plt.subplots(len(pollutants), 1, figsize=(10, 25), sharex=False)\n","\n","for i, pollutant in enumerate(pollutants):\n","    ax = axes[i]\n","    ax.plot(monthly_avg['Date'], monthly_avg[pollutant], marker='.', linestyle='-', color='blue', alpha=0.7, label='Monthly Average')\n","    ax.set_ylabel(f'{pollutant} (ug/m3)')\n","    ax.set_title(f'{pollutant} Monthly Average Concentration Over Time')\n","    ax.legend()\n","    ax.set_xlabel('Date')\n","    ax.tick_params(axis='x', rotation=45)  # Rotate x-axis labels\n","\n","# Adjust spacing between subplots\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","\n","# Set a common title for the figure\n","fig.suptitle('Monthly Average Concentrations of Pollutants Over Time', fontsize=16)\n","\n","plt.show()"],"metadata":{"id":"MN_VYyTcteY8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["monthly_avg"],"metadata":{"id":"hSpI-gJ641UJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Monthwise Plot**"],"metadata":{"id":"DyrM5fYS03_S"}},{"cell_type":"code","source":["# Group by Month to calculate the monthly average for each pollutant\n","monthly_avg = df.groupby('month')[pollutants].mean()\n","\n","# Plotting the monthly average for each pollutant\n","fig, axes = plt.subplots(len(pollutants), 1, figsize=(10, 15), sharex=False)\n","\n","# Define month names for x-axis labels\n","month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","\n","for i, pollutant in enumerate(pollutants):\n","    ax = axes[i]\n","    ax.plot(month_names, monthly_avg[pollutant], marker='o', linestyle='-', color='blue', alpha=0.7, label='Monthly Average')\n","    ax.set_ylabel(f'{pollutant} (ug/m3)')\n","    ax.set_title(f'{pollutant} Monthly Average Concentration')\n","    ax.legend()\n","    ax.set_xlabel('Month')  # Set x-axis label\n","\n","# Adjust spacing between subplots\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","\n","# Set a common title for the figure\n","fig.suptitle('Monthly Average Concentrations of Pollutants Over Time', fontsize=16)\n","\n","plt.show()"],"metadata":{"id":"rBCNRxgcuayU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Most Dominant Pollutants:**"],"metadata":{"id":"Hrs-s3pFALot"}},{"cell_type":"code","source":["pollutants = ['PM2.5', 'PM10', 'Nitric', 'NH3', 'CO', 'SO2', 'O3', 'BTX']\n","pol=df1[pollutants].mean()\n","pollutants_df=pol.to_frame().reset_index()\n","pollutants_df.columns=['Pollutant','Level']\n","pollutants_df"],"metadata":{"id":"6gVTFsW7AfbI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(11,8))\n","\n","labels = pollutants_df['Pollutant']\n","explode = [0, 0.1, 0, 0, 0, 0, 0,0]  # Exploding the first slice (PM2.5)\n","\n","plt.title('Dominant Pollutants in India')\n","wedges, texts, autotexts = plt.pie(\n","    pollutants_df['Level'],\n","    explode=explode,\n","    autopct='%1.1f%%',\n","    shadow=True,\n","    startangle=0\n",")\n","\n","plt.axis('equal')  # Ensures the pie chart is drawn as a circle\n","\n","# Adding legend\n","plt.legend(\n","    wedges,\n","    labels,\n","    title=\"Pollutants\",\n","    loc=\"center\",\n","    bbox_to_anchor=(1, 0, 0.5, 1)\n",")\n","\n","# Setting the properties of the percentage texts\n","plt.setp(autotexts, size=14, weight='bold')\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"Jmy7WNVHCbCm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Dominant Pollutant citywise**"],"metadata":{"id":"nt8yLkcKPQ2K"}},{"cell_type":"code","source":["import pandas as pd\n","\n","pollutants = ['PM2.5', 'PM10', 'Nitric', 'NH3', 'CO', 'SO2', 'O3', 'BTX']\n","\n","# Group data by 'State' and calculate the mean of each pollutant\n","statewise_pollution_means = df1.groupby('City')[pollutants].mean()\n","\n","# Find the dominant pollutant in each state\n","dominant_pollutant_by_state = statewise_pollution_means.idxmax(axis=1)\n","\n","# Convert the result to a DataFrame for better readability\n","dominant_pollutant_df = dominant_pollutant_by_state.reset_index()\n","dominant_pollutant_df.columns = ['City', 'Dominant Pollutant']\n","\n","# Display the results\n","dominant_pollutant_df\n"],"metadata":{"id":"iF-0gaYtHUoN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Correlation between the different Pollutants**"],"metadata":{"id":"_EvTvH94OVLO"}},{"cell_type":"code","source":["\n","# Filter the DataFrame to include only numeric columns\n","# This assumes you want to include only the pollutants columns\n","pollutants = ['PM2.5', 'PM10', 'Nitric', 'NH3', 'CO', 'SO2', 'O3', 'BTX']\n","numeric_pollutants_df = df1[pollutants]\n","\n","# Convert data to numeric (this will handle any non-numeric values)\n","numeric_pollutants_df = numeric_pollutants_df.apply(pd.to_numeric, errors='coerce')\n","\n","# Drop rows with any NaN values (if any)\n","numeric_pollutants_df = numeric_pollutants_df\n","\n","# Calculate the correlation matrix\n","correlation_matrix = numeric_pollutants_df.corr()\n","\n","# Plot the heatmap\n","plt.figure(figsize=(12, 8))\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1, center=0)\n","plt.title('Correlation Heatmap of Pollutants')\n","plt.show()\n"],"metadata":{"id":"-zHEyyv84ymb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numeric_pollutants_df.corr()"],"metadata":{"id":"rRkjXQfmCan3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Assuming df1 is your DataFrame and it contains the pollutant columns\n","pollutants = ['PM2.5', 'PM10', 'Nitric', 'NH3', 'CO', 'SO2', 'O3', 'BTX']\n","\n","# Filter the DataFrame to include only the pollutant columns\n","pollutants_df = df1[pollutants]\n","\n","# Ensure all columns are numeric\n","pollutants_df = pollutants_df.apply(pd.to_numeric, errors='coerce')\n","\n","# Drop rows with NaN values\n","pollutants_df = pollutants_df.dropna()\n","\n","# Create scatter plots between each pair of pollutants\n","# Use pairplot from seaborn to plot all pairwise scatter plots\n","sns.pairplot(pollutants_df, diag_kind='kde', plot_kws={'alpha':0.5})\n","plt.suptitle('Pairwise Scatter Plots of Pollutants', y=1.02)\n","plt.show()\n"],"metadata":{"id":"TcFHSo8JB2dR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Top 10 polluted Cities (based on Pollutants)**\n","\n","Let's now look at the Indian cities which contribute to maximum pollution. We shall output the top 10 cities in each pollutant category by mean concentration of the pollutant over the years."],"metadata":{"id":"ep700zRlqzJ9"}},{"cell_type":"code","source":["def max_polluted_city(pollutants):\n","    x1 = df[[pollutants,'City']].groupby([\"City\"]).mean().sort_values(by=pollutants,ascending=False).reset_index()\n","    x1[pollutants] = round(x1[pollutants],2)\n","    return x1[:10].style.background_gradient(cmap='OrRd')"],"metadata":{"id":"c9HzVVbjrUJ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display_html\n","\n","def display_side_by_side(*args):\n","    # Convert each DataFrame's Styler object to HTML and join them together\n","    html_str = ''\n","    for df in args:\n","        html_str += df._repr_html_()  # Use _repr_html_ to get the HTML representation\n","    display_html(html_str.replace('table', 'table style=\"display:inline;margin-right:20px;\"'), raw=True)\n","\n","# Example usage with your top pollutant DataFrames\n","pm2_5 = max_polluted_city('PM2.5')\n","pm10 = max_polluted_city('PM10')\n","no2 = max_polluted_city('Nitric')\n","so2 = max_polluted_city('SO2')\n","co = max_polluted_city('CO')\n","btx = max_polluted_city('BTX')\n","nh3=max_polluted_city('NH3')\n","ozone=max_polluted_city('O3')\n","air_qua=max_polluted_city('AQI')\n","\n","# Display the DataFrames side by side\n","display_side_by_side(pm2_5, pm10, no2, so2, co, btx,nh3,ozone,air_qua)\n"],"metadata":{"id":"44tPAsRi0xvN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Assuming df is your DataFrame with pollutant data\n","pollutant_columns = ['PM2.5','PM10','Nitric', 'NH3','CO', 'SO2','O3', 'BTX','AQI']\n","\n","# Step 1: Group by city and calculate mean pollutant concentrations\n","mean_pollutant_by_city = df.groupby('City')[pollutant_columns].mean()\n","\n","# Step 2: Find the top 10 cities for each pollutant\n","top_cities = {}\n","for pollutant in pollutant_columns:\n","    top_cities[pollutant] = mean_pollutant_by_city[pollutant].sort_values(ascending=False).head(10)\n","\n","# Step 3: Plotting\n","fig, axes = plt.subplots(len(pollutant_columns), 1, figsize=(10, 20))\n","\n","for i, pollutant in enumerate(pollutant_columns):\n","    axes[i].barh(top_cities[pollutant].index, top_cities[pollutant].values, color='skyblue')\n","    axes[i].set_title(f'Top 10 Cities by {pollutant}')\n","    axes[i].set_xlabel(f'{pollutant}')\n","    axes[i].invert_yaxis()  # Highest values on top\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"3l5-UpFa-G5C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the pollutant columns\n","pollutants = ['PM2.5', 'PM10', 'Nitric', 'NH3', 'CO', 'SO2', 'O3', 'BTX']\n","\n","# Calculate the average levels of pollutants for each city\n","city_pollution = df1.groupby('City')[pollutants].mean()\n","\n","import matplotlib.pyplot as plt\n","\n","# Plotting the average pollutants for each city\n","city_pollution.plot(kind=\"bar\",\n","                 figsize=(10,10),\n","                 stacked=True)\n","plt.title('Average Pollutant Levels Across Cities')\n","plt.xlabel('City')\n","plt.ylabel('Pollutant Level')\n","plt.show()\n"],"metadata":{"id":"6sutpFrUqijA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Top 10 polluted Cities (based on AQI values)**\n","\n","Let's now look at the Indian cities which contribute to maximum pollution using the AQI values. We shall output the top 10 cities in each pollutant category by mean concentration of the AQI values over the years."],"metadata":{"id":"YbawpS9g_Jzg"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Assuming 'df' is your DataFrame containing the data\n","\n","# Calculate the average AQI for each city\n","average_aqi_by_city = df.groupby('City')['AQI'].mean().reset_index()\n","\n","# Sort the cities by average AQI in descending order to find the most polluted\n","most_polluted_cities = average_aqi_by_city.sort_values(by='AQI', ascending=False)\n","\n","# Display the top 10 most polluted cities\n","top_10_most_polluted_cities = most_polluted_cities.head(25)\n","print(top_10_most_polluted_cities)\n"],"metadata":{"id":"pjH6bBybWA5V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Bar chart to show the average AQI of the top 10 most polluted cities\n","plt.figure(figsize=(12, 8))\n","plt.bar(top_10_most_polluted_cities['City'], top_10_most_polluted_cities['AQI'], color='blue')\n","plt.xlabel('Average AQI')\n","plt.xticks(rotation=90);\n","plt.ylabel('City')\n","plt.title('Top 10 Most Polluted Cities in India by Average AQI')\n","plt.show()\n"],"metadata":{"id":"xr5Lo5pUWGZr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Observations:**\n","\n","Here we see that Delhi has the highest AQI value among all the cities for the period of 2015-2020.\n","The next highest is Patna and the city with lowest AQI is Shillong."],"metadata":{"id":"XWaim1_Y3PAy"}},{"cell_type":"code","source":["delhi_df1=df1[df1.City == 'Delhi']\n","patna_df1=df1[df1.City == 'Patna']\n","gurugram_df1=df1[df1.City == 'Gurugram']\n","lucknow_df1=df1[df1.City == 'Lucknow']\n","talcher_df1=df1[df1.City == 'Talcher']"],"metadata":{"id":"31rYBCZRStah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["delhi_df1"],"metadata":{"id":"bYvoSo8ryJTp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["delhi_df1_yr=delhi_df1.groupby('Year')[selected_columns[4:13]].mean()\n","delhi_df1_yr"],"metadata":{"id":"YztZAFGIDoRP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["patna_df1_yr=patna_df1.groupby('Year')[selected_columns[4:13]].mean()\n","patna_df1_yr"],"metadata":{"id":"BmpRVxNCFF5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gurugram_df1_yr=gurugram_df1.groupby('Year')[selected_columns[4:13]].mean()\n","gurugram_df1_yr"],"metadata":{"id":"YCuFs_gKFQVX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lucknow_df1_yr=lucknow_df1.groupby('Year')[selected_columns[4:13]].mean()\n","lucknow_df1_yr"],"metadata":{"id":"JBn7pu1iFZuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["talcher_df1_yr=talcher_df1.groupby('Year')[selected_columns[4:13]].mean()\n","talcher_df1_yr"],"metadata":{"id":"S0yVzm3KFgCo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(delhi_df1_yr.index,delhi_df1_yr.AQI,'D:m')\n","plt.plot(patna_df1_yr.index,patna_df1_yr.AQI,'s-b')\n","plt.plot(gurugram_df1_yr.index,gurugram_df1_yr.AQI,'o--r')\n","plt.plot(lucknow_df1_yr.index,lucknow_df1_yr.AQI,'+-.g')\n","plt.plot(talcher_df1_yr.index,talcher_df1_yr.AQI,'s:y')\n","\n","plt.xlabel('Year')\n","plt.ylabel('Air Quality Index (AQI)')\n","\n","plt.title('AQI Comparision')\n","plt.legend(['Delhi','Patna','Gurugram','Lucknow','Talcher']);"],"metadata":{"id":"Z-FRnZyccvlF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Define the cities you're interested in\n","cities_ = ['Delhi', 'Patna', 'Gurugram', 'Lucknow', 'Talcher']\n","\n","# Create a figure with 5 subplots (one for each city)\n","fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n","axes = axes.flatten()  # Flatten the axes array for easier indexing\n","fig.suptitle('Monthly AQI Trends for Selected Cities', fontsize=16)\n","\n","for i, city in enumerate(cities_):\n","    city_df = df1[df1['City'] == city]\n","\n","    # Group by 'Year' and 'month' and calculate the mean for AQI\n","    city_monthly_avg = city_df.groupby(['Year', 'month'])['AQI'].mean().reset_index()\n","\n","    # Plotting the AQI trend for each city\n","    sns.lineplot(\n","        data=city_monthly_avg,\n","        x='month', y='AQI', hue='Year', palette='dark',\n","        markers=True, dashes=False, ax=axes[i]\n","    )\n","    axes[i].set_title(f'{city} Monthly AQI')\n","    axes[i].set_xlabel('Month')\n","    axes[i].set_ylabel('AQI')\n","\n","# Hide the last subplot if not used\n","if len(cities_) % 2 != 0:\n","    fig.delaxes(axes[-1])\n","\n","# Adjust the layout to make room for the titles and labels\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","\n","plt.show()\n"],"metadata":{"id":"aSrmP7AhlMFM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aqi_df=df1[['AQI','AQI_Bucket']]\n","aqi_df"],"metadata":{"id":"AJXzTLiyywoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aqi_df.dropna()"],"metadata":{"id":"6cW9iylIz_vM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idx=['Good','Satisfactory','Moderate','Poor','Very Poor','Severe']\n","aqi_bucket_df=aqi_df.AQI_Bucket.value_counts().to_frame().reindex(idx)\n","aqi_bucket_df.reset_index(inplace=True)\n","aqi_bucket_df.columns=['AQI_Bucket','Count']\n","aqi_bucket_df"],"metadata":{"id":"eHf5lTUe0Ej3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import matplotlib.ticker as ticker\n","\n","# Example DataFrame; replace with your actual DataFrames\n","# aqi_df is your DataFrame with 'AQI' and 'AQI_Bucket' columns\n","# aqi_bucket_df is your DataFrame with 'AQI_Bucket' and 'Count' columns\n","\n","fig, ax = plt.subplots(1, 2, figsize=(17, 7.5), squeeze=False)\n","\n","# Drawing the histogram for AQI values\n","sns.histplot(aqi_df, x='AQI', hue='AQI_Bucket', edgecolor=\".3\", linewidth=.5, log_scale=True, ax=ax[0,0])\n","ax[0,0].xaxis.set_major_formatter(ticker.ScalarFormatter())\n","ax[0,0].set_xticks([20,50,100,200,350,500])\n","ax[0,0].set_title(\"Distribution of AQI\")\n","\n","# Drawing the bar chart for AQI_Bucket values\n","sns.barplot(x='AQI_Bucket', y='Count', data=aqi_bucket_df, ax=ax[0,1])\n","ax[0,1].set_title('Air Quality of India')\n","ax[0,1].set_ylabel('Count')\n","ax[0,1].set_xlabel('Air Quality')\n","\n","# Show the plots\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"EL2un1ul0LM-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Assuming df1 is your DataFrame and contains the required columns\n","\n","# List of pollutants\n","pollutants = ['PM2.5', 'PM10', 'Nitric', 'NH3', 'CO', 'SO2', 'O3', 'BTX']\n","\n","# Calculate the average level of each pollutant for each city\n","city_pollutants_df = df1.groupby('City')[pollutants].mean().reset_index()\n","\n","# Melt the DataFrame to get it into long format suitable for plotting\n","city_pollutants_melted = city_pollutants_df.melt(id_vars='City', var_name='Pollutant', value_name='Level')\n","\n","# List of cities to plot\n","cities = ['Delhi', 'Patna', 'Gurugram', 'Lucknow', 'Talcher']\n","\n","# Filter the melted DataFrame to include only the cities of interest\n","city_pollutants_melted = city_pollutants_melted[city_pollutants_melted['City'].isin(cities)]\n"],"metadata":{"id":"M8FRQ4F57NUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create subplots for each city\n","fig, axes = plt.subplots(1, len(cities), figsize=(20, 5), squeeze=False)\n","fig.suptitle('Dominant Pollutants in Selected Cities')\n","\n","for i, city in enumerate(cities):\n","    # Filter the DataFrame for the current city\n","    city_data = city_pollutants_melted[city_pollutants_melted['City'] == city]\n","\n","    # Ensure the DataFrame is not empty\n","    if city_data.empty:\n","        continue\n","\n","    # Pie chart parameters\n","    labels = city_data['Pollutant']\n","    levels = city_data['Level']\n","    explode = [0.1] + [0] * (len(labels) - 1)  # Explode the first slice (most dominant pollutant)\n","\n","    # Plotting the pie chart\n","    wedges, texts, autotexts = axes[0, i].pie(\n","        levels,\n","        explode=explode,\n","        autopct='%1.1f%%',\n","        shadow=True,\n","        startangle=0\n","    )\n","\n","    # Setting title and properties\n","    axes[0, i].set_title(f'{city}')\n","    axes[0, i].axis('equal')  # Ensures the pie chart is drawn as a circle\n","\n","    # Adding legend\n","    axes[0, i].legend(\n","        wedges,\n","        labels,\n","        title=\"Pollutants\",\n","        loc=\"center left\",\n","        bbox_to_anchor=(1.1, 0, 0.5, 1)\n","    )\n","\n","    # Setting the properties of the percentage texts\n","    plt.setp(autotexts, size=12, weight='bold')\n","\n","# Adjust layout\n","plt.tight_layout(rect=[0, 0, 1, 1])  # Adjust layout to make room for the suptitle\n","\n","# Display the plot\n","plt.show()\n"],"metadata":{"id":"Um147iJZ77es"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Define lockdown period (you may need to adjust these dates based on your specific lockdown dates)\n","lockdown_start = '2020-03-25'  # Example lockdown start date\n","lockdown_end = '2020-05-31'    # Example lockdown end date\n","\n","# Convert date columns to datetime\n","df['Date'] = pd.to_datetime(df['Date'])\n","\n","# Filter data for lockdown period\n","lockdown_data = df[(df['Date'] >= lockdown_start) & (df['Date'] <= lockdown_end)]\n","\n","# Filter data for pre-lockdown period\n","pre_lockdown_data = df[df['Date'] < lockdown_start]\n","\n","# Define pollutants\n","pollutants = ['PM2.5', 'PM10', 'Nitric', 'NH3', 'CO', 'SO2', 'O3', 'BTX']\n","\n","# Calculate average levels of each pollutant during lockdown\n","lockdown_avg = lockdown_data[pollutants].mean().reset_index()\n","lockdown_avg.columns = ['Pollutant', 'Lockdown_Level']\n","\n","# Calculate average levels of each pollutant before lockdown\n","pre_lockdown_avg = pre_lockdown_data[pollutants].mean().reset_index()\n","pre_lockdown_avg.columns = ['Pollutant', 'Pre_Lockdown_Level']\n","\n","# Merge the two DataFrames\n","comparison_df = pd.merge(pre_lockdown_avg, lockdown_avg, on='Pollutant')\n","\n","# Plot the comparison\n","plt.figure(figsize=(12, 8))\n","\n","# Melt the DataFrame for easier plotting with seaborn\n","melted_df = comparison_df.melt(id_vars='Pollutant', var_name='Period', value_name='Level')\n","\n","# Plot\n","sns.barplot(x='Pollutant', y='Level', hue='Period', data=melted_df, palette='coolwarm')\n","\n","plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n","plt.title('Effect of Lockdown on Levels of Individual Pollutants')\n","plt.xlabel('Pollutant')\n","plt.ylabel('Average Level')\n","plt.legend(title='Period')\n","plt.tight_layout()\n","\n","plt.show()\n"],"metadata":{"id":"fnS9CjO1_vtB"},"execution_count":null,"outputs":[]}]}